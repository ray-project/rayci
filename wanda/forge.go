package wanda

import (
	"fmt"
	"log"
	"os"
	"path/filepath"
	"runtime"
	"strings"
	"time"

	"github.com/google/go-containerregistry/pkg/authn"
	cranename "github.com/google/go-containerregistry/pkg/name"
	crane "github.com/google/go-containerregistry/pkg/v1"
	"github.com/google/go-containerregistry/pkg/v1/remote"
)

// Build builds a container image from the given specification file, and builds
// all its dependencies in topological order.
// In RayCI mode, dependencies are assumed built by prior pipeline steps; only
// the root is built.
func Build(specFile string, config *ForgeConfig) error {
	if config == nil {
		config = &ForgeConfig{}
	}

	wandaSpecsFile := config.WandaSpecsFile
	if wandaSpecsFile == "" {
		wandaSpecsFile = filepath.Join(config.WorkDir, ".wandaspecs")
	}

	lookup := lookupFunc(os.LookupEnv)
	if config.EnvFile != "" {
		envfileVars, err := ParseEnvFile(config.EnvFile)
		if err != nil {
			return fmt.Errorf("parse envfile: %w", err)
		}
		lookup = func(key string) (string, bool) {
			if v, ok := envfileVars[key]; ok {
				return v, true
			}
			return os.LookupEnv(key)
		}
	}

	graph, err := buildDepGraph(specFile, lookup, config.NamePrefix, wandaSpecsFile)
	if err != nil {
		return fmt.Errorf("build dep graph: %w", err)
	}

	forge, err := NewForge(config)
	if err != nil {
		return fmt.Errorf("make forge: %w", err)
	}
	forge.lookup = lookup

	// In RayCI mode, only build the root (deps built by prior pipeline steps).
	order := graph.Order
	if config.RayCI {
		order = []string{graph.Root}
	}

	for _, name := range order {
		rs := graph.Specs[name]

		log.Printf("building %s (from %s)", name, rs.Path)

		if err := forge.Build(rs.Spec); err != nil {
			return fmt.Errorf("build %s: %w", name, err)
		}
	}

	// Extract artifacts only for the root spec.
	if config.ArtifactsDir != "" {
		rootSpec := graph.Specs[graph.Root].Spec
		if len(rootSpec.Artifacts) > 0 {
			rootTag := forge.workTag(rootSpec.Name)
			if err := forge.ExtractArtifacts(rootSpec, rootTag); err != nil {
				return fmt.Errorf("extract artifacts: %w", err)
			}
		}
	}

	return nil
}

// Forge is a forge to build container images.
type Forge struct {
	config *ForgeConfig

	workDir string

	remoteOpts []remote.Option

	cacheHitCount int

	docker *dockerCmd

	lookup lookupFunc
}

// NewForge creates a new forge with the given configuration.
func NewForge(config *ForgeConfig) (*Forge, error) {
	absWorkDir, err := filepath.Abs(filepath.FromSlash(config.WorkDir))
	if err != nil {
		return nil, fmt.Errorf("abs path for work dir: %w", err)
	}

	f := &Forge{
		config:  config,
		workDir: absWorkDir,
		remoteOpts: []remote.Option{
			remote.WithAuthFromKeychain(authn.DefaultKeychain),
			remote.WithPlatform(crane.Platform{
				OS:           runtime.GOOS,
				Architecture: runtime.GOARCH,
			}),
		},
	}
	f.docker = f.newDockerCmd()

	return f, nil
}

func (f *Forge) cacheHit() int { return f.cacheHitCount }

func (f *Forge) addSrcFile(ts *tarStream, src string) {
	ts.addFile(src, nil, filepath.Join(f.workDir, filepath.FromSlash(src)))
}

func (f *Forge) isRemote() bool             { return f.config.isRemote() }
func (f *Forge) workTag(name string) string { return f.config.workTag(name) }
func (f *Forge) cacheTag(digest string) string {
	return f.config.cacheTag(digest)
}

func (f *Forge) newDockerCmd() *dockerCmd {
	return newDockerCmd(&dockerCmdConfig{
		bin:             f.config.DockerBin,
		useLegacyEngine: runtime.GOOS == "windows",
	})
}

func (f *Forge) resolveBases(froms []string) (map[string]*imageSource, error) {
	m := make(map[string]*imageSource)
	namePrefix := f.config.NamePrefix

	for _, from := range froms {
		if strings.HasPrefix(from, "@") { // A local image.
			name := strings.TrimPrefix(from, "@")
			src, err := resolveDockerImage(f.docker, from, name)
			if err != nil {
				return nil, fmt.Errorf("resolve local image %s: %w", from, err)
			}
			m[from] = src
			continue
		}

		if namePrefix != "" && strings.HasPrefix(from, namePrefix) {
			if !f.isRemote() {
				// Treat it as a local image.
				src, err := resolveDockerImage(f.docker, from, from)
				if err != nil {
					return nil, fmt.Errorf(
						"resolve prefixed local image %s: %w", from, err,
					)
				}
				m[from] = src
				continue
			}

			// An image in the work namespace. It is generated by a previous
			// job, and we need to pull it from the work repo.
			fromName := strings.TrimPrefix(from, f.config.NamePrefix)
			workTag := f.workTag(fromName)

			src, err := resolveRemoteImage(from, workTag, f.remoteOpts...)
			if err != nil {
				return nil, fmt.Errorf(
					"resolve remote work image %s: %w", from, err,
				)
			}
			m[from] = src
			continue
		}

		// A normal remote image that we need to pull from the network.
		src, err := resolveRemoteImage(from, from, f.remoteOpts...)
		if err != nil {
			return nil, fmt.Errorf("resolve remote image %s: %w", from, err)
		}
		m[from] = src
	}
	return m, nil
}

// ExtractArtifacts copies Artifacts from a built image to ArtifactsDir.
// Supports glob patterns in src paths (e.g., "/*.whl").
//
// NOTE(andrew-anyscale): We use `docker cp` for copying file-by-file rather than
// a single more efficient method of extracting from `docker export` because
// docker cp handles cross-platform issues reliably. If this becomes a bottleneck
// indicated by the log-line below, we can consider using a different approach.
func (f *Forge) ExtractArtifacts(spec *Spec, imageTag string) error {
	d := f.newDockerCmd()
	artifactsDir := f.config.ArtifactsDir

	// In RayCI mode, clear the artifacts directory to avoid stale artifacts.
	if f.config.RayCI {
		if err := os.RemoveAll(artifactsDir); err != nil {
			return fmt.Errorf("clear artifacts dir: %w", err)
		}
	}

	if err := os.MkdirAll(artifactsDir, 0755); err != nil {
		return fmt.Errorf("create artifacts dir: %w", err)
	}

	log.Printf("extracting %d artifact(s) from %s", len(spec.Artifacts), imageTag)
	extractStart := time.Now()

	// In remote mode, pull the image first (it may only exist in registry after
	// cache hit).
	if f.isRemote() {
		if err := d.run("pull", imageTag); err != nil {
			return fmt.Errorf("pull image for extraction: %w", err)
		}
	}

	containerID, err := d.createContainer(imageTag)
	if err != nil {
		return fmt.Errorf("create container: %w", err)
	}
	defer func() {
		if err := d.removeContainer(containerID); err != nil {
			log.Printf("warning: failed to remove container %s: %v", containerID, err)
		}
	}()

	// Lazily list container files only if needed for glob matching.
	var containerFiles []string
	var extracted []string

	for _, a := range spec.Artifacts {
		if err := a.Validate(); err != nil {
			return fmt.Errorf("invalid artifact: %w", err)
		}

		if a.HasGlob() && containerFiles == nil {
			var err error
			containerFiles, err = d.listContainerFiles(containerID)
			if err != nil {
				return fmt.Errorf("list container files: %w", err)
			}
		}

		srcs := a.ResolveSrcs(containerFiles)
		if len(srcs) == 0 {
			if a.Optional {
				log.Printf("warning: no files matched pattern: %s", a.Src)
				continue
			}
			return fmt.Errorf("no files matched pattern: %s", a.Src)
		}

		dstBase, err := a.ResolveDst(artifactsDir)
		if err != nil {
			return fmt.Errorf("resolve artifact dst: %w", err)
		}

		// Treat dst as a directory (preserving original filenames) when:
		// - dst ends with "/" (explicit directory), or
		// - multiple source files (can't rename all to one name)
		dstIsDir := strings.HasSuffix(a.Dst, "/") || len(srcs) > 1

		if dstIsDir {
			if err := os.MkdirAll(dstBase, 0755); err != nil {
				return fmt.Errorf("create dir for artifact %s: %w", a.Dst, err)
			}
		} else {
			if err := os.MkdirAll(filepath.Dir(dstBase), 0755); err != nil {
				return fmt.Errorf("create dir for artifact %s: %w", a.Dst, err)
			}
		}

		for _, src := range srcs {
			dst := dstBase
			if dstIsDir {
				dst = filepath.Join(dstBase, filepath.Base(src))
			}

			if err := d.copyFromContainer(containerID, src, dst); err != nil {
				if a.Optional {
					log.Printf("warning: optional artifact not found: %s", src)
					continue
				}
				return fmt.Errorf("copy artifact %s: %w", src, err)
			}
			if abs, err := filepath.Abs(dst); err == nil {
				dst = abs
			}
			extracted = append(extracted, dst)
		}
	}

	log.Printf("extracted %d artifact(s) in %v:", len(extracted), time.Since(extractStart).Round(time.Millisecond))
	for _, f := range extracted {
		log.Printf("  %s", f)
	}
	return nil
}

// Build builds a container image from the given specification.
func (f *Forge) Build(spec *Spec) error {
	// Prepare the tar stream.
	ts := newTarStream()

	files, err := listSrcFiles(f.workDir, spec.Srcs, spec.Dockerfile)
	if err != nil {
		return fmt.Errorf("list src files: %w", err)
	}
	for _, file := range files {
		f.addSrcFile(ts, file)
	}

	in := newBuildInput(ts, spec.BuildArgs)

	froms, err := f.resolveBases(spec.Froms)
	if err != nil {
		return fmt.Errorf("resolve bases: %w", err)
	}
	in.froms = froms

	inputCore, err := in.makeCore(spec.Dockerfile, f.lookup)
	if err != nil {
		return fmt.Errorf("make build input core: %w", err)
	}
	inputCore.Epoch = f.config.Epoch

	caching := !spec.DisableCaching

	inputDigest, err := inputCore.digest()
	if err != nil {
		return fmt.Errorf("compute build input digest: %w", err)
	}
	log.Println("build input digest:", inputDigest)

	cacheTag := f.cacheTag(inputDigest)
	workTag := f.workTag(spec.Name)

	// Add all the tags.

	// Work tag is the tag we use to save the image in the work repo.
	in.addTag(workTag)
	in.addTag(cacheTag)

	// When running on rayCI, we only need the workTag and the cacheTag.
	// Otherwise, add extra tags.
	if !f.config.RayCI {
		// Name tag is the tag we use to reference the image locally.
		// It is also what can be referenced by following steps.
		if f.config.NamePrefix != "" {
			nameTag := f.config.NamePrefix + spec.Name
			in.addTag(nameTag)
		}
		for _, tag := range spec.Tags { // And add extra tags.
			in.addTag(tag)
		}
	}

	if caching && !f.config.Rebuild {
		if f.isRemote() {
			ct, err := cranename.NewTag(cacheTag)
			if err != nil {
				return fmt.Errorf("parse cache tag %q: %w", cacheTag, err)
			}
			wt, err := cranename.NewTag(workTag)
			if err != nil {
				return fmt.Errorf("parse work tag %q: %w", workTag, err)
			}

			desc, err := remote.Get(ct, f.remoteOpts...)
			if err != nil {
				log.Printf("cache image miss: %v", err)
			} else {
				log.Printf("cache hit: %s", desc.Digest)
				f.cacheHitCount++

				log.Printf("tag output as %s", workTag)
				if err := remote.Tag(wt, desc, f.remoteOpts...); err != nil {
					return fmt.Errorf("tag cache image: %w", err)
				}

				return nil // and we are done.
			}
		} else {
			info, err := f.docker.inspectImage(cacheTag)
			if err != nil {
				return fmt.Errorf("check cache image: %w", err)
			}
			if info != nil {
				log.Printf("cache hit: %s", info.ID)
				f.cacheHitCount++

				for _, tag := range in.tagList() {
					log.Printf("tag output as %s", tag)
					if tag != cacheTag {
						if err := f.docker.tag(cacheTag, tag); err != nil {
							return fmt.Errorf("tag cache image: %w", err)
						}
					}
				}
				return nil // and we are done.
			}
		}
	}

	inputHints := newBuildInputHints(spec.BuildHintArgs, f.lookup)

	// Now we can build the image.
	// Always use a new dockerCmd so that it can run in its own environment.
	d := f.newDockerCmd()
	d.setWorkDir(f.workDir)

	if err := d.build(in, inputCore, inputHints); err != nil {
		return fmt.Errorf("build docker: %w", err)
	}

	// Push the image to the work repo with workTag and cacheTag if needed.
	if f.isRemote() {
		if err := d.run("push", workTag); err != nil {
			return fmt.Errorf("push docker: %w", err)
		}

		// Save cache result too.
		if caching && !f.config.ReadOnlyCache {
			if err := d.run("push", cacheTag); err != nil {
				return fmt.Errorf("push cache: %w", err)
			}
		}
	}

	return nil
}
